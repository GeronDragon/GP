
<!-- saved from url=(0050)http://translate.googleusercontent.com/translate_f -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></head><body><pre>深机器学习，向纵深发展人工智能研究

一，简介

模仿的效率和稳健性由人的大脑代表的信息已经在人工智能研究的一个核心挑战了几十年。人类是造成前感官数据收到无数的一天每一秒，并以某种方式能够捕捉到的方式，使得其未来以简洁的方式使用这些数据的关键方面。 50年前，理查德·贝尔曼，谁介绍动态规划理论和开创最优控制的领域，断言数据的高维在许多科学和工程应用的根本障碍。主要的困难是产生，特别是在模式分类应用的情况中，是该学习复杂性与数据的维数线性增加呈指数增长。他创造了这个现象维度[1]的诅咒。克服“诅咒”的主流方法是预先处理数据的方式，将减少它的维数到它可以有效地进行处理，例如通过分类引擎。这个维数降低方案通常被称为特征提取。其结果，可以认为，后面许多模式识别系统的情报已转移到人工程化的特征提取过程中，这有时是很有挑战性的，高度依赖于应用的[2]。此外，如果不完整或错误的特征是前 - 牵引的，在分类过程中固有的性能受到限制。最近的神经科学的研究结果提供了洞察管理信息表示在哺乳动物大脑的原则，导致新的想法设计代表的信息系统。一个重要的发现一直认为新皮层，它与许多的认知能力有关，并没有明确预处理感觉信号，而是允许它们通过一个复杂的层级传播[3]的模块，随着时间的推移，学会的表示基于它们显示出[4]的规律性意见。这一发现促使深机器学习，侧重于计算模型的信息表达，表现出类似的特征，以使大脑皮层的子域的出现。

除了现实生活中的数据的空间维度，时间分量也起着关键的作用。图案的观测序列往往传达一个意思观察者，其中，该序列的独立片段将很难孤立地解读。含义往往是从在时间上接近收到事件或观察推断[5] [6]。为此目的，建模的观测的时间部分在有效的信息的表示的关键作用。捕获时空相关性，基于在观测规律性，因此被视为对深学习系统的一个基本目的。

假设鲁棒深学习实现，这将是可能的培养在一个大组观察结果，后来提取信号，例如一个分级网络从该网络到一个相对简单的分类引擎鲁棒模式识别的目的。稳健这里指的是表现出分类不变性变换和扭曲，包括噪声，缩放，旋转，不同的光照条件下，位移等不同范围的能力

本文提供建议在过去十年的主流深学习方法和研究方向的概述。必须强调的是每种方法都有优点和缺点，这取决于它正在使用的应用程序和上下文是重要的。因此，本文提出了深入的机器学习领域和一些观点的当前状态的总结到它如何可能演变。卷积神经网络（细胞神经网络）和深度信念网络（动态Bayesian网络）（及其各自的变化）都集中在主要是因为它们都很好地建立在深厚的学习领域，并显示为今后的工作大有希望。第二节介绍了细胞神经网络，并随后用如下的动态Bayesian网络在第三节的细节。为优良的进一步深入了解在这些技术的基础，读者可以参考文献[7]。第四节包含了目前建议的等深架构。第五节包含一个简短的说明这是如何的研究已经影响政府和行业举措。结论提供了深层次架构的潜在影响的角度来看，以及仍然存在需要回答的关键问题。

II。卷积神经网络

细胞神经网络[8] [9]是一个家庭中使用特别设计的二维数据多层神经网络，如图像和视频。细胞神经网络是由早期工作在时间延迟神经网络（TDNN），这降低学习计算要求通过共享权数在时间维度的，并且旨在对语音和时间序列处理[53]的影响。细胞神经网络是第一个真正成功的深度学习的方法，其中一个层次的许多层，成功地练就了一身健壮的方式。 CNN的是拓扑结构或架构，充分利用空间和时间的关系，以减少必须学会参数的数量，从而提高了在一般的前馈反向传播培训的选择。细胞神经网络提出的由最小数据预处理出于要求深刻学习框架。在细胞神经网络，所述图像（称为一个本地感受野）的一小部分被当作输入该分层结构的最低层。信息通常通过网络的不同层中传播，由此在每一层数字滤波以获得所观察到的数据的显着特征的应用。该方法提供不变性转移，规模和旋转的水平为局部感受野使神经元或处理单元使用基本功能，如面向边或角。

其中一个关于这个专题的重要论文[8]介绍细胞神经网络对笔迹分析问题的应用程序。本质上，该输入图像被卷积用一组N小的过滤器，其系数被训练，或被使用的一些标准预先确定。因此，网络的第一（或最低）层由“的特征图”，这是在卷积过程的结果，具有的特征的添加剂偏压以及可能的压缩或正常化。此初始阶段之后是子采样（通常为2 3 2平均运算），该进一步降低维数，并提供一定的鲁棒性，以空间变化（见图2）。二次取样特征图然后接收加权和训练的偏见，最终传播通过激活功能。这方面的一些变体，每层[13]或多个映射[8]的求和少至一个地图存在。

当加权小，激活函数是近似线性的，其结果是所述图像的模糊;其他加权可导致激活输出类似于一个AND或OR功能。这些输出形成一个新的特征图，然后将其通过卷积，子采样和激活功能流程的另一序列通过，如示于图3。该过程可以重复的任意次数。应当指出的是，随后的层可以结合一个或多个先前的层;例如，在[8]所述的最初六个月特征映射相结合以形成在随后的层16的特征图。如在[33]中描述的，细胞神经网络创建他们不变性由被称为“特征池”（图3中在S层）的方法，以对象的翻译。然而，特征池是通过手的网络主办单位，没有经过培训或系统了解到精雕细琢;在细胞神经网络，该池通过在学习过程中，但基本的机构（输入到S层的组合，例如）参数由网络设计者设置“调整”。最后，在过程的最后阶段，激活输出被转发到产生该系统的最终输出的常规的前馈神经网络。

在细胞神经网络的层次和空间信息之间的亲密关系使得它们非常适合于图像处理和理解，他们一般在自主提取显着特征，从图像表现良好。在某些情况下，Gabor滤波器已被用来作为初始预处理步骤以模拟到视觉激发[10]人类视觉响应。在最近的工作中，研究人员已应用细胞神经网络的各种机器学习的问题，包括人脸检测[11] [13]，文档分析[38]，和语音检测[12]。细胞神经网络有最近[25]被训练用时间相干目标利用的帧到帧的一致性在找到视频，尽管这目标不必是特定于细胞神经网络。

三。深信念网络

动态Bayesian网络，在最初推出的[14]，是站在对比的是传统的神经网络的歧视性质概率生成模型。生成模型提供过观察数据和标签的联合概率分布，促进两个P的估计（观察|标签）以及P（标签|观察），而判别模型限定于后者，P（标签|观察）。动态Bayesian网络解决所遇到的问题时，传统上施加反向传播到deeplylayered神经网络，即：（1）用于训练，（2）慢的学习（即会聚）倍，（3）参数不足选择技术设置大量标记数据必要性那导致糟糕的局部最优解。

动态Bayesian网络都用限制波尔兹曼机，一个类型的神经网络的几层（见图1）。这些网络“限制”到一个可见层和单隐层，在连接层之间形成（在层内单位未连接）。隐藏的单位进行培训，以捕捉那些在可见的单位观察高阶数据的相关性。最初，除了顶部的两个层，其形成一个相联存贮器，一个DBN的层仅由定向自上而下生成权重连接。 RBMS是有吸引力的作为结构单元，在更传统的和深分层乙状结肠信念网络，由于它们易于学习这些连接权。以获得生成的权重，在初始训练前发生在无监督贪婪层 - 层的方式，由什么顿所称对比发散[15]启动。在这个训练阶段，一个矢量v被呈现给可见单位转发值到隐藏的单位。朝着相反的，在可见部输入然后被随机企图重建原始输入找到。最后，这些新的可见神经元的激活被转发，使得一个步骤重建隐藏单元激活，小时，可以实现。执行这些来回步骤是称为Gibbs抽样的方法，以及在隐藏激活和可见输入的相关的差异形成的基础重量的更新。训练时间显著降低，因为它可以证明，只有一个单一的步骤是必要的近似最大似然学习。添加到网络中每一层都提高了训练数据，我们可以认为的真正提高表达能力的logprobability。这项有意义的扩张，与未标记数据的利用相结合，在任何深度学习应用的重要组成部分。

在顶部两层，权重被连接在一起，以使得下层的输出提供参考线索或连结为顶层为“准”以其存储器内容。我们经常遇到的问题，其中判别性能的终极关怀，如中在分类任务。一个DBN后，可以通过反向传播利用标记的数据预培训提高判别性能进行微调。此时，一组标签附着到顶层（扩大相联存储器），以澄清类别边界，通过该一组新的自下而上，识别权重被学习网络中。它已在[16]已经表明，这种网络经常表现比那些训练有素只与反向传播较好。这可以通过以下事实时，才需要反向传播为动态Bayesian网络上执行的重量（参数）空间中的局部搜索，超速训练和收敛时间相对于传统的前馈神经网络被直观地说明。

运用动态Bayesian网络的MNIST手写字符识别任务时获得的性能结果表明显著改善了前馈网络。引入动态Bayesian网络之后不久，更透彻的分析示于[17]固化它们与无监督的任务使用以及连续值的输入。上的问题而增加的变化[18] [19]进一步的测试示出动态Bayesian网络的恢复力（以及其它深架构）。

动态Bayesian网络的灵活性最近扩大[20]，通过引入卷积深层信念网络（CDBNs）的概念。动态Bayesian网络不固有地嵌入关于输入图像的二维结构的信息，即输入是简单矢量格式的图像矩阵。与此相反，CDBNs利用相邻像素的引进了具有什么被称为卷积RBMS是提供一种具有高尺寸图像缩放以及平移不变生成模型的空间关系。动态Bayesian网络目前没有明确处理学习观测量之间的时间关系，虽然最近有工作在堆叠颞RBMS [22]或这些的概括，配成颞卷积机[23]，用于学习的序列。这样的序列学习者的音频信号处理问题，从而动态Bayesian网络已经取得了进展最近[24]的应用，提供了一个途径令人振奋的未来研究。

发生静态图像测试动态Bayesian网络和细胞神经网络最常见的与手写数字的MNIST数据库[27]和加州理工学院-101的各种数据库对象（属于101类）[28]。每个体系结构的分类错误率可以在[19] [20] [21]中找到。为应用于MNIST数据库的各种机器学习技术的全面和TODATE性能比较中[27]提供的。

有关动态Bayesian网络最近的作品包括使用堆叠自动编码器代替RBMS在传统的动态Bayesian网络[17] [18] [21]。这种努力产生的可训练用相同的原则动态Bayesian网络，但在这些层的参数较少严格深多层神经网络架构。不像动态Bayesian网络，自动编码器使用的判别模型从其中输入样本空间不能由结构进行采样，使得它更难以解释什么网络被捕获在其内部表示。然而，它已被证明[21]该去噪autoencoders，其中在训练期间利用随机腐败，可以堆叠以产生泛化性能是可比（且在某些情况下，更好的是）传统动态Bayesian网络。对于单个去噪autoencoder训练过程对应于用于生成模型如RBMS的目标。

IV。最近提出的深度学习架构

有迹象表明，尝试新皮层模型计算的几个结构。这些模型已被灵感来源，如[42]，它试图在图像理解的各种计算相映射到皮层区域。随着时间的推移，这些模型进行了细化，但视觉处理过的层次结构中的核心概念一直保持。这些模型援引胡贝尔和维塞尔[44]，这是基于对猫的视觉皮层细胞研究的简单到复杂的细胞组织。

类似的组织由细胞神经网络以及其他深层次的模型使用（如Neocognitron [40] [41] [43]和HMAX [32] [45]），还更“明确的”皮层模型寻求更强映射他们的架构，以生物为灵感的车型。具体地，他们试图通过各种机制，如时间分析，其中时间被认为是在学习过程中不可分割的元件来解决学习和不变性的问题。

一个突出的例子是在Numenta公司[30] [33]开发的分层时间记忆（HTM）。 HTMS具有分级结构的基础上在[39]中所描述的概念和承受相似的其他工作有关的皮质电路的建模。与特定焦点上的视觉信息表示，在一个HTM分级结构的最低一级接收来自输入图像的一个小区域的输入。较高层次的对应于较大的区域（或感受域），因为它们将多个下感受域的表示构造。除了整个层次结构的层中的缩放变化，存在于每个层，这是由翻译或扫描输入图像本身的创建的一个重要的时间为基础的方面。

在学习阶段，第一层编译最常见的输入模式，并分配索引给他们。时间关系建模为过渡的概率从一个输入序列到另一个使用图形分割技术聚集在一起。当这个阶段的学习结束时，随后的（第二）层符连接的当前观测输入的索引从它的子模块和学习的最常见的串联作为字母表（另一组公共输入的序列，但在更高的级别）。高层的表征然后可以作为反馈提供下降到较低水平的模块。在较低的水平，反过来，结合此更广泛的代表性信息到它自己的推理的制剂。这个过程被重复，在层次结构的每一层。后一个网络进行训练，使用贝叶斯置信传播算法[46]，以确定给定的信念在层次结构（其对应于最宽的图像范围）的最高层的最可能的输入模式进行图像识别。在文献中提出的其他架构，这类似于HTMS，包括分层绗缝的SOM米勒和隆梅尔[47]认为采用两级空间聚类和使用selforganizing地图颞集群和贝肯的神经抽象金字塔[48]。

最近由作家为实现强大的信息表示引入的框架是深时空推理网（德斯坦）模型[26]。在此框架下，一个共同的皮质电路（或节点）填充整个层次，并且每个这些节点的独立和并行操作以所有其他节点。这个解决方案是不限制为一层接一层训练程序，使得用于执行并行处理平台了很大的吸引力。节点独立地通过使用一个信念状态构建体，其增量更新作为层次结构呈现数据的表征图形。

这条规则是由两个结构：一个较系统的状态怎么可能是观察，P段（观察|状态），而另一个代表怎么可能状态的状态转换从上面给出的反馈，P（后续状态|状态，反馈）。第一构建体是无监督和通过观测从动纯粹，而第二个，调制第一，嵌入到模式观测的动态。增量聚类小心用于估计观测分布，而状态转换是基于频率估计。有人认为，该方案的价值在于它的简单和重复结构，促进多模态表示和简单的培训。

表1提供了本文介绍的主流深机器学习方法的简要总结比较。

五，深入学习应用

已经有一些研究表明深学习方法的有效性在各种应用领域。除了MNIST手写挑战[27]，也有在面部检测[10]应用[51]，语音识别和检测[12]，一般对象识别[9]，自然语言处理[24]，和机器人。数据增长和丰富的多感官信息的现实是无可否认的一个挑战，而且在许多军事以及民用的应用，如先进的监视系统中反复出现的主题。因此，在深机器学习的兴趣不仅仅限于学术研究。近日，美国国防部高级研究计划局（DARPA）已经宣布了一项研究计划专注于深度学习[29]。一些私人机构，包括Numenta [30]和Binatix [31]，都集中在商业化深度学习技术与应用广泛的领域他们的注意力。

六。前进的道路

深机器学习是一个活跃的研究领域。仍有大量的工作要在提高学习的过程，其中，目前的重点是贷款肥沃的想法，从机器学习的其他领域，特别是在降维的背景下完成的。一个例子包括在最近的工作稀疏编码[57]，其中数据的固有的高维数是通过使用压缩传感理论的降低，允许信号具有非常小的数的基矢量的精确表示。另一个例子是半监督歧学习[58]，其中数据的维数降低通过测量训练数据样本之间的相似性，然后突出这些相似性测量值到低维空间。此外，更多的灵感和技术，可能会发现，从进化规划AP proaches [59，60]，其中概念自适应学习和核心架构的变化可以用最少的工程工作学习。

一些使得需要立即关注的核心问题包括：如何不特定方案刻度相对于所述输入的维数（这在图像可以在百万）？什么是捕捉短期和长期的时间依赖一个有效的框架？如何多式联运感官信息最自然给定的架构框架内融合？什么是可用于增加一个给定深度学习技术，以提高耐用性和不变性扭曲或丢失的数据的正确注意机制？如何做各种解决方案图平行促进加工加速处理平台？

虽然深度学习已经成功地应用于具有挑战性的模式推断任务，该领域的目标是远远超出任务的具体应用。这个范围可能使各种方法的比较，日益复杂并可能会通过必要研究界的共同努力来解决。还应当指出的是，尽管深度学习技术提供了广阔的发展前景的一些特定领域的任务可能不直接由这些计划的改善。一个例子是识别和读取的路由号码在银行支票的底部。虽然这些数字是人类可读的，它们是由哪些专业读者可以在非常高的数据速率[49]完美认限制的字符集。同样，虹膜识别是不是人类通常执行任务;的确，无需培训，1虹膜看起来非常相似，另一对未经训练的眼睛，但工程系统可产生候选虹膜图像与图像数据库之间的匹配以高精度和准确度以用作唯一标识符[50]。最后，最近的事态发展在面部识别[51]显示性能相对于人类相当于其匹配大批考生查询图像的能力，潜在地匹配远远超过大多数人能回忆[52]。尽管如此，这些仍然高度具体例，并且是一个冗长的特征工程优化进程（以及多年的研究）结果是不映射到其他更一般的应用。此外，深学习平台也可以从工程的特点，同时学习其设计的系统通常缺乏更复杂的表述中受益。

尽管开放的研究问题和无数的事实领域仍然处于起步阶段，这是非常清楚的，关于深发展机器学习系统取得的进展无疑将形成一般机器学习和人工智能系统的未来。

插图的坚定信念网络框架。

卷积和分采样过程：在卷积过程包括卷积的输入（图像为第一级或特征的地图为后级）与可训练滤波器FX然后加入一个可训练偏压BX，以产生卷积层Cx的。子采样包括求和一个邻域（四个像素），加权由标量WX + 1，加入可训练偏压BX + 1，并通过一个S形函数以产生一个大致2倍更小的特征地图Sx的+ 1。

卷积神经网络的概念性的一例。输入图像进行卷积具有三个可训练滤波器和偏压，如图2以产生三个特征图在C1级。各组中的特征图的四个像素相加，加权，结合一个偏压，并通过S形函数，在S2中，以产生三个特征图。这些被再次过滤，以产生C 3级。在层次结构然后产生S4在类似于S2中的方式。最后这些像素值进行栅格化，并作为一个单独的矢量输入到“常规”神经网络在输出。

主流深机器学习方法表我总结。
APPROACH（缩写）。
无监督训练前？
生成VS.判别。
注意事项

卷积神经网络（细胞神经网络）DEEP信念网络（DBNS）
NO判别利用空间/时间关系，
REDUCE学习要求
乐于助人生成多分层回归神经网络
训练了与能量最小化方法
STACKED（降噪）
AUTO-编码器
乐于助人的判别（降噪
编码器映射到
生成模型）
称取经受压STACKED神经网络
编码THROUGH
重建误差
分层时空
存储器（HTM）[30]
交变空间识别的NO生成层次
及其与监督时空推理蛋鸡
学习方法AT顶层
DEEP时空
推理网络（DESTIN）
无监督的NO歧视层次时空
贝叶斯态 - 态聚类单位
TRANSITIONS和自上而下的反馈
</pre></body></html>